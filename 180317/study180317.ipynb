{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "study180317.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7NdWpOn8CQba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. 헬로우 딥러닝 MNIST\n",
        "\n",
        "![대체 텍스트](https://i.imgur.com/Un7aQtW.png)\n",
        "\n",
        "출처 : 밑바닥부터 시작하는 딥러닝\n",
        "\n",
        "MNIST란? 0-9까지의 손글씨로 쓴 숫자 데이터\n",
        "\n",
        "미니배치 : 데이터를 적당한 크기로 잘라서 학습\n",
        "\n",
        "ex) 60,000장의 훈련 데이터중에서 100장을 무작위 뽑아서 100장만을 학습 (밑바닥부터 시작하는 딥러닝에서 나온 내용)\n",
        "\n",
        "에포크 : 학습 데이터 전체를 한 바퀴 도는 것"
      ]
    },
    {
      "metadata": {
        "id": "TwNKPhU_BlmP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d3ce8326-10d2-407c-c240-40e57e0a2d2b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520754541511,
          "user_tz": -540,
          "elapsed": 42625,
          "user": {
            "displayName": "sj jin",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107618035827318999649"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "# 텐서플로우에 기본 내장된 mnist 모듈을 이용하여 데이터를 로드합니다.\n",
        "# 지정한 폴더에 MNIST 데이터가 없는 경우 자동으로 데이터를 다운로드합니다.\n",
        "# one_hot 옵션은 레이블을 동물 분류 예제에서 보았던 one_hot 방식의 데이터로 만들어줍니다.\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "######\n",
        "# 입력 값의 차원은 [배치크기, 특성값] 으로 되어 있습니다.\n",
        "# 손글씨 이미지는 28x28 픽셀로 이루어져 있고, 이를 784개의 특성값으로 정합니다.\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "# 결과는 0~9 의 10 가지 분류를 가집니다.\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "# 신경망의 레이어는 다음처럼 구성합니다.\n",
        "# 784(입력 특성값)\n",
        "#   -> 256 (히든레이어 뉴런 갯수) -> 256 (히든레이어 뉴런 갯수)\n",
        "#   -> 10 (결과값 0~9 분류)\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "# 입력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "# L1 레이어의 출력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "# 최종 모델의 출력값은 W3 변수를 곱해 10개의 분류를 가지게 됩니다.\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "for epoch in range(15):\n",
        "    total_cost = 0\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        # 텐서플로우의 mnist 모델의 next_batch 함수를 이용해\n",
        "        # 지정한 크기만큼 학습할 데이터를 가져옵니다.\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
        "        total_cost += cost_val\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1),\n",
        "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
        "\n",
        "print('최적화 완료!')\n",
        "\n",
        "#########\n",
        "# 결과 확인\n",
        "######\n",
        "# model 로 예측한 값과 실제 레이블인 Y의 값을 비교합니다.\n",
        "# tf.argmax 함수를 이용해 예측한 값에서 가장 큰 값을 예측한 레이블이라고 평가합니다.\n",
        "# 예) [0.1 0 0 0.7 0 0.2 0 0 0 0] -> 3\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도:', sess.run(accuracy,\n",
        "                        feed_dict={X: mnist.test.images,\n",
        "                                   Y: mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "Epoch: 0001 Avg. cost = 0.415\n",
            "Epoch: 0002 Avg. cost = 0.151\n",
            "Epoch: 0003 Avg. cost = 0.099\n",
            "Epoch: 0004 Avg. cost = 0.070\n",
            "Epoch: 0005 Avg. cost = 0.053\n",
            "Epoch: 0006 Avg. cost = 0.042\n",
            "Epoch: 0007 Avg. cost = 0.033\n",
            "Epoch: 0008 Avg. cost = 0.026\n",
            "Epoch: 0009 Avg. cost = 0.019\n",
            "Epoch: 0010 Avg. cost = 0.019\n",
            "Epoch: 0011 Avg. cost = 0.015\n",
            "Epoch: 0012 Avg. cost = 0.013\n",
            "Epoch: 0013 Avg. cost = 0.013\n",
            "Epoch: 0014 Avg. cost = 0.013\n",
            "Epoch: 0015 Avg. cost = 0.011\n",
            "최적화 완료!\n",
            "정확도: 0.9801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sKcwFGEJFHzI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![대체 텍스트](https://i.imgur.com/tGpF9Mz.png)\n",
        "\n",
        "출처 : 밑바닥부터 시작하는 딥러닝\n",
        "\n",
        "드롭아웃 : 학습 시 전체 신경망 중 일부만을 사용하도록 하는 것"
      ]
    },
    {
      "metadata": {
        "id": "2_6zB320FvZn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {},
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "269c15b1-6388-4075-83ae-47134ba35806",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520755603043,
          "user_tz": -540,
          "elapsed": 98005,
          "user": {
            "displayName": "sj jin",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107618035827318999649"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "######\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "# 텐서플로우에 내장된 함수를 이용하여 dropout 을 적용합니다.\n",
        "# 함수에 적용할 레이어와 확률만 넣어주면 됩니다. 겁나 매직!!\n",
        "L1 = tf.nn.dropout(L1, keep_prob)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, keep_prob)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "for epoch in range(30):\n",
        "    total_cost = 0\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "        _, cost_val = sess.run([optimizer, cost],\n",
        "                               feed_dict={X: batch_xs,\n",
        "                                          Y: batch_ys,\n",
        "                                          keep_prob: 0.8})\n",
        "        total_cost += cost_val\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1),\n",
        "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
        "\n",
        "print('최적화 완료!')\n",
        "\n",
        "#########\n",
        "# 결과 확인\n",
        "######\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도:', sess.run(accuracy,\n",
        "                        feed_dict={X: mnist.test.images,\n",
        "                                   Y: mnist.test.labels,\n",
        "                                   keep_prob: 1}))\n",
        "\n",
        "#########\n",
        "# 결과 확인 (matplot)\n",
        "######\n",
        "labels = sess.run(model,\n",
        "                  feed_dict={X: mnist.test.images,\n",
        "                             Y: mnist.test.labels,\n",
        "                             keep_prob: 1})\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(10):\n",
        "    subplot = fig.add_subplot(2, 5, i + 1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
        "    subplot.imshow(mnist.test.images[i].reshape((28, 28)),\n",
        "                   cmap=plt.cm.gray_r)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "Epoch: 0001 Avg. cost = 0.418\n",
            "Epoch: 0002 Avg. cost = 0.164\n",
            "Epoch: 0003 Avg. cost = 0.114\n",
            "Epoch: 0004 Avg. cost = 0.090\n",
            "Epoch: 0005 Avg. cost = 0.072\n",
            "Epoch: 0006 Avg. cost = 0.061\n",
            "Epoch: 0007 Avg. cost = 0.053\n",
            "Epoch: 0008 Avg. cost = 0.046\n",
            "Epoch: 0009 Avg. cost = 0.040\n",
            "Epoch: 0010 Avg. cost = 0.038\n",
            "Epoch: 0011 Avg. cost = 0.034\n",
            "Epoch: 0012 Avg. cost = 0.033\n",
            "Epoch: 0013 Avg. cost = 0.030\n",
            "Epoch: 0014 Avg. cost = 0.029\n",
            "Epoch: 0015 Avg. cost = 0.026\n",
            "Epoch: 0016 Avg. cost = 0.026\n",
            "Epoch: 0017 Avg. cost = 0.023\n",
            "Epoch: 0018 Avg. cost = 0.020\n",
            "Epoch: 0019 Avg. cost = 0.022\n",
            "Epoch: 0020 Avg. cost = 0.022\n",
            "Epoch: 0021 Avg. cost = 0.022\n",
            "Epoch: 0022 Avg. cost = 0.018\n",
            "Epoch: 0023 Avg. cost = 0.018\n",
            "Epoch: 0024 Avg. cost = 0.021\n",
            "Epoch: 0025 Avg. cost = 0.020\n",
            "Epoch: 0026 Avg. cost = 0.016\n",
            "Epoch: 0027 Avg. cost = 0.016\n",
            "Epoch: 0028 Avg. cost = 0.016\n",
            "Epoch: 0029 Avg. cost = 0.018\n",
            "Epoch: 0030 Avg. cost = 0.015\n",
            "최적화 완료!\n",
            "정확도: 0.9833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAENCAYAAACCb1WXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+3syRs6cSAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1d7c6f89b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rrPSE9e7lMU6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. 붓꽃 데이터\n",
        "\n",
        "https://www.kaggle.com/uciml/iris/data\n",
        "\n",
        "캐글 데이터 참조 \n",
        "\n",
        "원본데이터 Iris.csv 참조\n",
        "\n",
        "https://thebook.io/006723/ch04/01/\n",
        "Iris 각 특성값들 참조"
      ]
    },
    {
      "metadata": {
        "id": "uTGTyJLClNvX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "b5604e9c-7bc3-42ec-a2fb-11ddc52eda55",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520847764215,
          "user_tz": -540,
          "elapsed": 3417,
          "user": {
            "displayName": "sj jin",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107618035827318999649"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.set_random_seed(777)\n",
        "\n",
        "# 가공한 붓꽃 트레이닝 데이터 입력\n",
        "xy = np.loadtxt('https://raw.githubusercontent.com/Crpediem/deeprunning-study/master/180317/Iris_train.csv',delimiter=',',\n",
        "                dtype=np.float32)\n",
        "x_data = xy[:,0:4]\n",
        "y_data = xy[:,4:7]\n",
        "\n",
        "# 가공한 붓꽃 테스트 데이터 입력\n",
        "test_xy = np.loadtxt('https://raw.githubusercontent.com/Crpediem/deeprunning-study/master/180317/Iris_test.csv',delimiter=',',\n",
        "                dtype=np.float32)\n",
        "\n",
        "x_test = test_xy[:,0:4]\n",
        "y_test = test_xy[:,4:7]\n",
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "######\n",
        "X = tf.placeholder(tf.float32, [None, 4])\n",
        "Y = tf.placeholder(tf.float32, [None, 3])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([4, 10], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "L1 = tf.nn.dropout(L1, keep_prob)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([10, 10], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, keep_prob)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([10, 3], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for step in range(1000):\n",
        "    sess.run(optimizer, feed_dict={X: x_data, Y: y_data, keep_prob: 0.8})\n",
        "\n",
        "    if (step + 1) % 100 == 0:\n",
        "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data, keep_prob: 0.8}))\n",
        "\n",
        "#########\n",
        "# 결과 확인\n",
        "# 0: Iris-setosa 1: Iris-versicolor, 2: Iris-virginica\n",
        "######\n",
        "prediction = tf.argmax(model, 1)\n",
        "target = tf.argmax(Y, 1)\n",
        "print('예측값:', sess.run(prediction, feed_dict={X: x_test, keep_prob: 1}))\n",
        "print('실제값:', sess.run(target, feed_dict={Y: y_test, keep_prob: 1}))\n",
        "\n",
        "is_correct = tf.equal(prediction, target)\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test, keep_prob: 1}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 0.23863082\n",
            "200 0.23964703\n",
            "300 0.18831006\n",
            "400 0.23864982\n",
            "500 0.19743586\n",
            "600 0.19411115\n",
            "700 0.18276615\n",
            "800 0.19053736\n",
            "900 0.20052955\n",
            "1000 0.2167687\n",
            "예측값: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2]\n",
            "실제값: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2]\n",
            "정확도: 100.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JbV9NeOJl8_N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## csv 파일 데이터 분류\n",
        "\n",
        "#### 1단계. 데이터 다듬기 \n",
        "\n",
        "캐글의 원본 csv에서 train과 test에서 사용되지 않을 id값과 label값을 삭제하고\n",
        "분류되는 값인 Iris-setosa, Iris-versicolor, Iris-virginica을 one-hot 형식으로 변환시켜줍니다.\n",
        "예) Iris-setosa = 100, Iris-versicolor = 010, Iris-virginica = 001\n",
        "\n",
        "#### 2단계. train과 test 데이터 나누기\n",
        "\n",
        "분류한 값을 저장 후 test와 train할 값을 나누어 각각 다른 csv로 저장합니다.\n",
        "\n",
        "#### 3단계. python list split\n",
        "\n",
        "생성한 csv에서 학습할 값과 분류되는 값을 분류하여 x_data,y_data에 저장합니다.\n",
        "test할 데이터도 동일하게 진행합니다."
      ]
    },
    {
      "metadata": {
        "id": "oZ-3RG9eM6mV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Wine data\n",
        "\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
        "\n",
        "위 주소에서 제공하는 데이터를 가지고 위의 소개한 방법으로 csv파일 분류을 동일하게 진행하여 학습해보도록 하겠습니다.\n"
      ]
    },
    {
      "metadata": {
        "id": "AykS3QhdqsZJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 7
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "9ed3444a-2aa8-4be3-b9b3-ef83e4b99d6f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520990309495,
          "user_tz": -540,
          "elapsed": 3186,
          "user": {
            "displayName": "sj jin",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107618035827318999649"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 가공한 트레이닝 데이터 입력\n",
        "xy = np.loadtxt('https://raw.githubusercontent.com/Crpediem/deeprunning-study/master/180317/wine_train.csv',delimiter=',',\n",
        "                dtype=np.float32)\n",
        "x_data = xy[:,0:13]\n",
        "y_data = xy[:,13:16]\n",
        "\n",
        "# 가공한 테스트 데이터 입력\n",
        "test_xy = np.loadtxt('https://raw.githubusercontent.com/Crpediem/deeprunning-study/master/180317/wine_test.csv',delimiter=',',\n",
        "                dtype=np.float32)\n",
        "\n",
        "x_test = test_xy[:,0:13]\n",
        "y_test = test_xy[:,13:16]\n",
        "\n",
        "# print(x_data)\n",
        "# print(y_data)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "#####\n",
        "X = tf.placeholder(tf.float32, [None, 13])\n",
        "Y = tf.placeholder(tf.float32, [None, 3])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([13, 100], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "L1 = tf.nn.dropout(L1, keep_prob)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([100, 100], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, keep_prob)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([100, 3], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for step in range(1000):\n",
        "    sess.run(optimizer, feed_dict={X: x_data, Y: y_data, keep_prob: 0.8})\n",
        "\n",
        "    if (step + 1) % 100 == 0:\n",
        "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data, keep_prob: 0.8}))\n",
        "\n",
        "#########\n",
        "# 결과 확인\n",
        "######\n",
        "prediction = tf.argmax(model, 1)\n",
        "target = tf.argmax(Y, 1)\n",
        "print('예측값:', sess.run(prediction, feed_dict={X: x_test, keep_prob: 1}))\n",
        "print('실제값:', sess.run(target, feed_dict={Y: y_test, keep_prob: 1}))\n",
        "\n",
        "is_correct = tf.equal(prediction, target)\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test, keep_prob: 1}))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 0.5879292\n",
            "200 0.1710964\n",
            "300 0.11573343\n",
            "400 0.08524342\n",
            "500 0.07245682\n",
            "600 0.066718794\n",
            "700 0.082000956\n",
            "800 0.09255613\n",
            "900 0.0823765\n",
            "1000 0.080762655\n",
            "예측값: [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n",
            "실제값: [0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n",
            "정확도: 100.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4zc039MQG2FF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. dropout 효과\n",
        "\n",
        "![대체 텍스트](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/With_Without_Dropout.png)\n",
        "\n",
        "출처 :  https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/dropout_layer.html\n",
        "\n",
        "드롭아웃 정리 전, 후 에러율입니다.\n",
        "\n",
        "차이가 꽤나 나는 것을 보실 수 있습니다.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}